{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving LLMs with MLflow: Leveraging Custom PyFunc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<a href=\"https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/llms/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm.ipynb\" class=\"notebook-download-btn\"><i class=\"fas fa-download\"></i>Download this Notebook</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Introduction\n",
    "\n",
    "This tutorial guides you through saving and deploying Large Language Models (LLMs) using a custom `pyfunc` with MLflow, ideal for models not directly supported by MLflow's default transformers flavor.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Understand the need for custom `pyfunc` definitions in specific model scenarios.\n",
    "- Learn to create a custom `pyfunc` to manage model dependencies and interface data.\n",
    "- Gain insights into simplifying user interfaces in deployed environments with custom `pyfunc`.\n",
    "\n",
    "#### The Challenge with Default Implementations\n",
    "While MLflow's `transformers` flavor generally handles models from the HuggingFace Transformers library, some models or configurations might not align with this standard approach. In such cases, like ours, where the model cannot utilize the default `pipeline` type, we face a unique challenge of deploying these models using MLflow.\n",
    "\n",
    "#### The Power of Custom PyFunc\n",
    "To address this, MLflow's custom `pyfunc` comes to the rescue. It allows us to:\n",
    "\n",
    "- Handle model loading and its dependencies efficiently.\n",
    "- Customize the inference process to suit specific model requirements.\n",
    "- Adapt interface data to create a user-friendly environment in deployed applications.\n",
    "\n",
    "Our focus will be on the practical application of a custom `pyfunc` to deploy LLMs effectively within MLflow's ecosystem.\n",
    "\n",
    "By the end of this tutorial, you'll be equipped with the knowledge to tackle similar challenges in your machine learning projects, leveraging the full potential of MLflow for custom model deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Considerations Before Proceeding\n",
    "\n",
    "#### Hardware Recommendations\n",
    "This guide demonstrates the usage of a particularly large and intricate Large Language Model (LLM). Given its complexity:\n",
    "\n",
    "- **GPU Requirement**: It's **strongly advised** to run this example on a system with a CUDA-capable GPU that possesses at least 64GB of VRAM.\n",
    "- **CPU Caution**: While technically feasible, executing the model on a CPU can result in extremely prolonged inference times, potentially taking tens of minutes for a single prediction, even on top-tier CPUs. The final cell of this notebook is deliberately not executed due to the limitations with performance when running this model on a CPU-only system. However, with an appropriately powerful GPU, the total runtime of this notebook is ~8 minutes end to end.\n",
    "\n",
    "#### Execution Recommendations\n",
    "If you're considering running the code in this notebook:\n",
    "\n",
    "- **Performance**: For a smoother experience and to truly harness the model's capabilities, use hardware aligned with the model's design.\n",
    "\n",
    "- **Dependencies**: Ensure you've installed the recommended dependencies for optimal model performance. These are crucial for efficient model loading, initialization, attention computations, and inference processing:\n",
    "\n",
    "```bash\n",
    "pip install xformers==0.0.20 einops==0.6.1 flash-attn==v1.0.3.post0 triton-pre-mlir@git+https://github.com/vchiley/triton.git@triton_pre_mlir#subdirectory=python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwh/.conda/envs/mlflow-llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "\n",
    "import accelerate\n",
    "import torch\n",
    "import transformers\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the Model and Tokenizer\n",
    "\n",
    "First, we need to download our model and tokenizer. Here's how we do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the MPT-7B instruct model and tokenizer to a local directory cache\n",
    "# snapshot_location = snapshot_download(repo_id=\"mosaicml/mpt-7b-instruct\", local_dir=\"mpt-7b\")\n",
    "snapshot_location = '/home/lwh/Documents/Code/MLflow-LLM/mpt-7b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Custom PyFunc\n",
    "\n",
    "Now, let's define our custom `pyfunc`. This will dictate how our model loads its dependencies and how it performs predictions. Notice how we've wrapped the intricacies of the model within this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPT(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        This method initializes the tokenizer and language model\n",
    "        using the specified model snapshot directory.\n",
    "        \"\"\"\n",
    "        # Initialize tokenizer and language model\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "            context.artifacts[\"snapshot\"], padding_side=\"left\"\n",
    "        )\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(\n",
    "            context.artifacts[\"snapshot\"], trust_remote_code=True\n",
    "        )\n",
    "        # If you are running this in a system that has a sufficiently powerful GPU with available VRAM,\n",
    "        # uncomment the configuration setting below to leverage triton.\n",
    "        # Note that triton dramatically improves the inference speed performance\n",
    "\n",
    "        # config.attn_config[\"attn_impl\"] = \"triton\"\n",
    "\n",
    "        self.model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "            context.artifacts[\"snapshot\"],\n",
    "            config=config,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        # NB: If you do not have a CUDA-capable device or have torch installed with CUDA support\n",
    "        # this setting will not function correctly. Setting device to 'cpu' is valid, but\n",
    "        # the performance will be very slow.\n",
    "        # self.model.to(device=\"cpu\")\n",
    "        # If running on a GPU-compatible environment, uncomment the following line:\n",
    "        self.model.to(device=\"cuda\")\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def _build_prompt(self, instruction):\n",
    "        \"\"\"\n",
    "        This method generates the prompt for the model.\n",
    "        \"\"\"\n",
    "        INSTRUCTION_KEY = \"### Instruction:\"\n",
    "        RESPONSE_KEY = \"### Response:\"\n",
    "        INTRO_BLURB = (\n",
    "            \"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\"\n",
    "        )\n",
    "\n",
    "        return f\"\"\"{INTRO_BLURB}\n",
    "        {INSTRUCTION_KEY}\n",
    "        {instruction}\n",
    "        {RESPONSE_KEY}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def predict(self, context, model_input, params=None):\n",
    "        \"\"\"\n",
    "        This method generates prediction for the given input.\n",
    "        \"\"\"\n",
    "        prompt = model_input[\"prompt\"][0]\n",
    "\n",
    "        # Retrieve or use default values for temperature and max_tokens\n",
    "        temperature = params.get(\"temperature\", 0.1) if params else 0.1\n",
    "        max_tokens = params.get(\"max_tokens\", 1000) if params else 1000\n",
    "\n",
    "        # Build the prompt\n",
    "        prompt = self._build_prompt(prompt)\n",
    "\n",
    "        # Encode the input and generate prediction\n",
    "        # NB: Sending the tokenized inputs to the GPU here explicitly will not work if your system does not have CUDA support.\n",
    "        # If attempting to run this with GPU support, change 'cpu' to 'cuda' for maximum performance\n",
    "        encoded_input = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output = self.model.generate(\n",
    "            encoded_input,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            max_new_tokens=max_tokens,\n",
    "        )\n",
    "\n",
    "        # Removing the prompt from the generated text\n",
    "        prompt_length = len(self.tokenizer.encode(prompt, return_tensors=\"pt\")[0])\n",
    "        generated_response = self.tokenizer.decode(\n",
    "            output[0][prompt_length:], skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        return {\"candidates\": [generated_response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Prompt\n",
    "\n",
    "One key aspect of our custom `pyfunc` is the construction of a model prompt. Instead of the end-user having to understand and construct this prompt, our custom `pyfunc` takes care of it. This ensures that regardless of the intricacies of the model's requirements, the end-user interface remains simple and consistent.\n",
    "\n",
    "Review the method `_build_prompt()` inside our class above to see how custom input processing logic can be added to a custom pyfunc to support required translations of user-input data into a format that is compatible with the wrapped model instance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import ColSpec, DataType, ParamSchema, ParamSpec, Schema\n",
    "\n",
    "# Define input and output schema\n",
    "input_schema = Schema(\n",
    "    [\n",
    "        ColSpec(DataType.string, \"prompt\"),\n",
    "    ]\n",
    ")\n",
    "output_schema = Schema([ColSpec(DataType.string, \"candidates\")])\n",
    "\n",
    "parameters = ParamSchema(\n",
    "    [\n",
    "        ParamSpec(\"temperature\", DataType.float, np.float32(0.1), None),\n",
    "        ParamSpec(\"max_tokens\", DataType.integer, np.int32(1000), None),\n",
    "    ]\n",
    ")\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=parameters)\n",
    "\n",
    "\n",
    "# Define input example\n",
    "input_example = pd.DataFrame({\"prompt\": [\"What is Reinfoncement learning?\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the experiment that we're going to be logging our custom model to\n",
    "\n",
    "If the experiment doesn't already exist, MLflow will create a new experiment with this name and will alert you that it has created a new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/lwh/Documents/Code/MLflow-LLM/mlruns/566831076974487757', creation_time=1721702364783, experiment_id='566831076974487757', last_update_time=1721702364783, lifecycle_stage='active', name='mpt-7b-instruct-evaluation', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you are running this tutorial in local mode, leave the next line commented out.\n",
    "# Otherwise, uncomment the following line and set your tracking uri to your local or remote tracking server.\n",
    "\n",
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"mpt-7b-instruct-evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 79/79 [00:06<00:00, 12.64it/s]  \n",
      "2024/07/23 11:03:53 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - sentencepiece (current: uninstalled, required: sentencepiece)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "# Get the current base version of torch that is installed, without specific version modifiers\n",
    "torch_version = torch.__version__.split(\"+\")[0]\n",
    "\n",
    "# Start an MLflow run context and log the MPT-7B model wrapper along with the param-included signature to\n",
    "# allow for overriding parameters at inference time\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        \"mpt-7b-instruct\",\n",
    "        python_model=MPT(),\n",
    "        # NOTE: the artifacts dictionary mapping is critical! This dict is used by the load_context() method in our MPT() class.\n",
    "        artifacts={\"snapshot\": snapshot_location},\n",
    "        pip_requirements=[\n",
    "            f\"torch=={torch_version}\",\n",
    "            f\"transformers=={transformers.__version__}\",\n",
    "            f\"accelerate=={accelerate.__version__}\",\n",
    "            \"einops\",\n",
    "            \"sentencepiece\",\n",
    "        ],\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/23 11:04:05 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - sentencepiece (current: uninstalled, required: sentencepiece)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/lwh/.cache/huggingface/modules/transformers_modules/mpt-7b/configuration_mpt.py:114: UserWarning: alibi or rope is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi or rope is turned on, setting `learned_pos_emb` to `False.`')\n",
      "/home/lwh/.cache/huggingface/modules/transformers_modules/mpt-7b/configuration_mpt.py:141: UserWarning: If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".\n",
      "  warnings.warn(UserWarning('If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".'))\n",
      "/home/lwh/.conda/envs/mlflow-llm/lib/python3.11/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/lwh/.conda/envs/mlflow-llm/lib/python3.11/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/lwh/.conda/envs/mlflow-llm/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidates': ['Machine learning is a field of study that uses algorithms to learn from data. Machine learning algorithms are mostly based on statistical learning methods. Machine learning algorithms are used for a variety of tasks, including pattern recognition, text classification, speech recognition, and computer vision. Machine learning is often used in conjunction with data mining and artificial intelligence.\\n        \\n        In simple terms, machine learning algorithms learn from the data and improve over time. For example, the Google search algorithm uses machine learning to improve its search results for you over time.']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The execution of this is commented out for the purposes of runtime on CPU.\n",
    "# If you are running this on a system with a sufficiently powerful GPU, you may uncomment and interface with the model!\n",
    "\n",
    "loaded_model.predict(pd.DataFrame(\n",
    "    {\"prompt\": [\"What is machine learning?\"]}), params={\"temperature\": 0.6, \"max_tokens\": 1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/home/lwh/.cache/huggingface/modules/transformers_modules/mpt-7b/attention.py:89: UserWarning: Propagating key_padding_mask to the attention module and applying it within the attention module can cause unnecessary computation/memory usage. Consider integrating into attn_bias once and passing that to each attention module instead.\n",
      "  warnings.warn('Propagating key_padding_mask to the attention module ' + 'and applying it within the attention module can cause ' + 'unnecessary computation/memory usage. Consider integrating ' + 'into attn_bias once and passing that to each attention ' + 'module instead.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'candidates': ['Reinforcement learning (RL) is an area of machine learning concerned with how agents maximize a reward in an environment. More specifically, it is a technique for learning the best action to take in a given situation, through trial and error. The agent tries out actions and receives feedback, either positive (reward) or negative (penalty), that tells it which actions are better or worse.\\n\\n        Reinforcement learning is a field of study that focuses on how to teach artificial intelligence to learn through trial and error. It is based on the idea of what is known as the \"reinforcement signal.\" The agent tries a certain action and receives feedback about how well that action worked. This feedback is then used to improve the agent\\'s behavior.\\n\\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n\\n        Reinforcement learning is a field of study that focuses on how to teach artificial intelligence to learn through trial and error. It is based on the idea of what is known as the \"reinforcement signal.\" The agent tries a certain action and receives feedback about the action. This feedback is then used to improve the agent\\'s behavior.\\n        \\n        Reinforcement learning is a machine learning technique that can help an agent learn to perform actions in a way that maximizes its long-term rewards. It\\'s a method of training an agent to do what is most beneficial for the agent, which is called the \"reward signal.\" The agent tries out actions and receives feedback, either positive (reward) or negative (penalty), that tells it which actions are better or worse.\\n        \\n        Reinforcement learning (RL) is an area of machine learning concerned with how agents maximize a reward in an environment. More specifically, it is a technique for learning the best action to take in a given situation, through trial and error. The agent tries out actions and receives feedback, either positive (reward) or negative (penalty), that tells it which actions are better or worse.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms that learn through trial and error. The agent performs an action, receives feedback about the action, and uses this feedback to improve its performance.\\n        \\n        In machine learning, the concept of reinforcement learning is used to describe a class of algorithms']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(pd.DataFrame(\n",
    "    {\"prompt\": [\"What is Reinfoncement learning?\"]}), params={\"temperature\": 0.6, \"max_tokens\": 1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Through this tutorial, we've seen the power and flexibility of MLflow's custom `pyfunc`. By understanding the specific needs of our model and defining a custom `pyfunc` to cater to those needs, we can ensure a seamless deployment process and a user-friendly interface.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
