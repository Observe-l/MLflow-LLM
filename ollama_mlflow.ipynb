{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf050cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "from termcolor import colored\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3150c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_database(document_path, database_save_directory, chunk_size=500, chunk_overlap=50, batch_size=100):\n",
    "    # Load text\n",
    "    loader = TextLoader(document_path)\n",
    "    raw_documents = loader.load()\n",
    "    print(f\"Loaded {len(raw_documents)} document(s)\")\n",
    "\n",
    "    # Smart splitting\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = splitter.split_documents(raw_documents)\n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "\n",
    "    # Embedding in batches\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "    faiss_db = None\n",
    "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Embedding chunks\"):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        if faiss_db is None:\n",
    "            faiss_db = FAISS.from_documents(batch, embedding_model)\n",
    "        else:\n",
    "            faiss_db.add_documents(batch)\n",
    "\n",
    "    faiss_db.save_local(database_save_directory)\n",
    "    return faiss_db\n",
    "\n",
    "\n",
    "\n",
    "def print_answer_formatted(answer, max_line_length=100):\n",
    "    \"\"\"\n",
    "    Prints the answer with the following requirements:\n",
    "    1. Max length of each line is 160.\n",
    "    2. <think> ... </think> content is printed in a light color.\n",
    "    3. After <think> content, print 2 empty lines.\n",
    "    \"\"\"\n",
    "    # Extract <think> ... </think> content\n",
    "    think_match = re.search(r\"<think>(.*?)</think>\", answer, re.DOTALL)\n",
    "    if think_match:\n",
    "        think_content = think_match.group(1).strip()\n",
    "        rest_content = answer.replace(think_match.group(0), \"\").strip()\n",
    "    else:\n",
    "        think_content = \"\"\n",
    "        rest_content = answer\n",
    "\n",
    "    # Helper to print with max line length\n",
    "    def print_wrapped(text, color=None):\n",
    "        words = text.split()\n",
    "        line = \"\"\n",
    "        for word in words:\n",
    "            if len(line) + len(word) + 1 <= max_line_length:\n",
    "                line += word + \" \"\n",
    "            else:\n",
    "                if color:\n",
    "                    print(colored(line.rstrip(), color))\n",
    "                else:\n",
    "                    print(line.rstrip())\n",
    "                line = word + \" \"\n",
    "        if line:\n",
    "            if color:\n",
    "                print(colored(line.rstrip(), color))\n",
    "            else:\n",
    "                print(line.rstrip())\n",
    "\n",
    "    # Print <think> content in light color (e.g., 'cyan')\n",
    "    if think_content:\n",
    "        print_wrapped(think_content, color=\"cyan\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Print the rest\n",
    "    if rest_content:\n",
    "        print_wrapped(rest_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d840032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary_directory = tempfile.mkdtemp()\n",
    "faiss_directory = \"faiss_database/CMAPSS_FD001/\"\n",
    "os.makedirs(faiss_directory, exist_ok=True)\n",
    "\n",
    "# doc_path = os.path.join(temporary_directory, \"docs.txt\")\n",
    "doc_path = \"local_text/CMAPSS_FD001.txt\"\n",
    "persist_dir = os.path.join(faiss_directory, \"faiss_index\")\n",
    "\n",
    "# fetch_and_save_documents(url_listings, doc_path)\n",
    "\n",
    "# Use smaller chunk size to avoid exceeding token limits\n",
    "# vector_db = create_faiss_database(doc_path, persist_dir,chunk_size=500, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4db14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwh/.conda/envs/ollama/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "2025/07/20 22:20:49 INFO mlflow.pyfunc: Inferring model signature from input example\n",
      "2025/07/20 22:20:49 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: TypeError(\"argument 'text': 'Series' object cannot be converted to 'PyString'\"). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38974df08c640d8ba9bc0069356e895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwh/.conda/envs/ollama/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "2025/07/20 22:20:58 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": {\n",
      "    \"query\": \"What is the CMAPSS dataset?\"\n",
      "  }\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: argument 'text': 'ndarray' object cannot be converted to 'PyString'\n",
      "2025/07/20 22:20:58 INFO mlflow.models.model: Found the following environment variables used during model inference: [OPENAI_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Ollama RAG\")\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "\n",
    "code_path = \"ollama_pyfunction.py\"\n",
    "example_input = {\"query\": \"What is the CMAPSS dataset?\"}\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        name=\"deepseek-r1-8b-CMAPSS\",\n",
    "        python_model=code_path,\n",
    "        artifacts={\n",
    "            \"persist_directory\": persist_dir,\n",
    "        },\n",
    "        input_example=example_input,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7874ef93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models:/m-e1b55123a0e24e208f62b2fe53ed9c91'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1f043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lwh/.conda/envs/ollama/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d952e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mHmm, the user has provided several lines of context from what looks like a dataset, all starting\u001b[0m\n",
      "\u001b[36mwith \"96\" and including engine IDs, time stamps, operation data, and sensor readings. They want me\u001b[0m\n",
      "\u001b[36mto explain what CMAPSS is based on this information. Looking at these examples, I can see that each\u001b[0m\n",
      "\u001b[36mrow contains an engine ID (first column), time of reading (second column), operation status in\u001b[0m\n",
      "\u001b[36mcolumns 3-4 or more depending on the dataset snippet, and then various sensor values. This appears\u001b[0m\n",
      "\u001b[36mto be a dataset related to machine performance monitoring, specifically for engines with multiple\u001b[0m\n",
      "\u001b[36msensors tracking different parameters over time. CMAPSS is likely an acronym - perhaps it stands\u001b[0m\n",
      "\u001b[36mfor something like China Manufacturer of Air Piston Engines Propulsion System Simulation? Given\u001b[0m\n",
      "\u001b[36mthat all these data points belong to engine 96 (from the examples), this would be a simulation\u001b[0m\n",
      "\u001b[36mdataset rather than real operational data, which makes sense as datasets with fixed engine IDs are\u001b[0m\n",
      "\u001b[36mtypically simulations. The user wants me to predict Remaining Useful Life (RUL) using this dataset.\u001b[0m\n",
      "\u001b[36mThis suggests they're working on predictive maintenance for engines or similar equipment. The\u001b[0m\n",
      "\u001b[36mCMAPSS dataset is commonly used in prognostics research, particularly for bearings and other\u001b[0m\n",
      "\u001b[36mrotating machinery components. I should explain that CMAPSS is a publicly available simulation\u001b[0m\n",
      "\u001b[36mdataset specifically designed for remaining useful life prediction tasks in mechanical systems like\u001b[0m\n",
      "\u001b[36maircraft engines or turbofan engines. It's part of the broader PHM (Prognostic and Health\u001b[0m\n",
      "\u001b[36mManagement) community datasets.\u001b[0m\n",
      "\n",
      "\n",
      "CMAPSS appears to be an acronym, likely related to a specific manufacturer or organization (\"China\n",
      "Manufacturer of Air Piston Engines Propulsion System Simulation\" is one common interpretation).\n",
      "Based on the context provided: 1. The dataset contains multiple rows for Engine ID \"96\". 2. Each\n",
      "row includes time stamps (second column) and various sensor readings. 3. Columns 3-5 seem to\n",
      "represent operation status. Therefore, CMAPSS is a publicly available simulation dataset commonly\n",
      "used in prognostics research for predicting the Remaining Useful Life (RUL) of mechanical systems,\n",
      "often focusing on components like bearings or engines under specific degradation conditions.\n"
     ]
    }
   ],
   "source": [
    "query1 = {\"query\": \"What is CMAPSS?\"}\n",
    "answer1 = loaded_model.predict(query1)\n",
    "print_answer_formatted (answer1['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df41c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35382/4122895577.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  vector_db.as_retriever().get_relevant_documents(\"What is GCPATr?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='0e6f8bef-d217-4ba1-874f-603842c02340', metadata={'source': 'local_text/paper.txt'}, page_content='In this work, we have used the GCPATr architecture that incorporates both graph convolution and position awareness into the standard transformer architecture. The overall processing pipeline of GCPATr is shown in Figure \\\\ref{Overall_GCPATr_Pipeline}. \\n\\nThe position aware spectral graph self-attention block is shown in Figure \\\\ref{SG_PA_SA_block} and the position aware self-attention block of PATr is shown in Figure \\\\ref{PA_SA_block}. Different from the position aware self-attention block of PATr \\\\cite{chattopadhyay2024position}, the linear query, key and value extractors have been replaced with spectral graph convolution operations in GCPATr. Other than this difference the working of the two blocks is the same.'),\n",
       " Document(id='895cf545-4560-4354-80da-d2344f4a2ae0', metadata={'source': 'local_text/paper.txt'}, page_content='The essence of the transformer architecture is its\\nmulti-head self-attention mechanism. It excels in extracting semantic correlations among elements in a long sequence, e.g. words in texts. Self-attention is intrinsically position or permutation invariant. Using various types of positional encoding techniques preserves some ordering information. However, there is still significant loss of ordering information especially in deep transformers where several layers of self-attention is applied. The work in \\\\cite{chattopadhyay2024position} proposed a position aware transformer architecture (PATr) with the the idea of permutation and position awareness being incorporated into the self-attention mechanism. PATr was shown to achieve state-of-the-art results in various domains. Another important observation in the case of multivariate time series data (such as those used for RUL prediction) is that it may have non-Euclidean dependencies. More precisely, we do not know about the interdependence between the multivariate time series. It is well known that the best way to model the interdependence in non-Euclidean data is to use Graph Convolution Networks (GCN) \\\\cite{bruna2014spectral, bronstein2017geometric}. The work in \\\\cite{chattopadhyay2025graph} propose the Graph Convolution Position Aware Transformer (GCPATr) architecture which enhances the non-Euclidean interdependency modeling power of PATr by incorporating graph convolution operations at critical places in its architecture.'),\n",
       " Document(id='53be2deb-995e-4cbd-ae95-65da32259cbc', metadata={'source': 'local_text/paper.txt'}, page_content='\\\\begin{equation} \\\\label{FedAvgEq}\\n    W_{glb}^{t+1} = W_{glb}^{t} + \\\\frac{\\\\sum_{n \\\\in N} D_{n}.\\\\Delta W_{n}^{t}}{\\\\sum_{n \\\\in N} D_{n}}\\n\\\\end{equation}\\n\\n\\\\subsection{Graph Convolution Position Aware Transformer}\\n\\n\\\\begin{figure*}[!t] \\n\\\\centering\\n\\\\subfloat[][Overall architecture of the Graph Convolution Position Aware Transformer.]{\\\\includegraphics[width=5in]{Fig1}\\n\\\\label{GCPATr_OA}}\\n\\\\hfill\\n\\\\centering\\n\\\\subfloat[][Multi-head Spectral Graph Position Aware Transformer layer.]{\\\\includegraphics[width=5in]{Fig2}\\n\\\\label{MH_GCPATr_block}}\\n\\\\hfill\\n\\\\centering\\n\\\\subfloat[][Position Aware Spectral Graph Self-Attention block.]{\\\\includegraphics[width=3.7in]{Fig3}\\n\\\\label{SG_PA_SA_block}}\\n\\\\hfill\\n\\\\centering\\n\\\\subfloat[][Position Aware Self-Attention block.]{\\\\includegraphics[width=3.2in]{Fig4}\\n\\\\label{PA_SA_block}}\\n\\\\hfill\\n\\\\caption{\\\\label{Overall_GCPATr_Pipeline} The processing pipeline of the GCPATr model and Position Aware Self-Attention block.}\\n\\\\end{figure*}'),\n",
       " Document(id='45f3e8ba-9983-4c7f-b61a-da210ad693c2', metadata={'source': 'local_text/paper.txt'}, page_content='GCPATr does not assume that the elements of $X^{t}$ to have an Euclidean graph structure. Consider the graph $G=(V, E, A)$. Here, $V$ denotes the set of nodes. Each node denotes a sensor. Since there are $K$ sensors, we have $|V| = K$. The set of edges in $G$ is denoted by $E$. An edge will exist between two nodes if there is some dependency between the respective input time series. Here, $A$ denotes the adjacency matrix. It is a $K \\\\times K$ square matrix, with $a_{ij}$ (the $i^{\\\\rm{th}}$ row and $j^{\\\\rm{th}}$ column element) denoting the amount of dependency between the respective input time series. An effective way of estimating the amount of dependency between two time series is by computing their covariance. We can compute the respective covariances using the training data. Our choice of adjacency matrix is shown in equation (\\\\ref{CovMatCalc}) below. Here, $X_{i} = [X^{1}_{i}, X^{2}_{i},...., X^{T}_{i}]$, $E[.]$ denotes the expectation operator, and ${\\\\rm{Tr}}(X_{j})$ denotes the transpose of $X_{j}$. The expectation is taken over the entire training data. Intuitively, $a_{ij} \\\\neq 0$ means that the reading from sensors denoted by nodes $i$ and $j$ are not independent. This becomes clear if we consider each sensor output as a random variable.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.as_retriever().get_relevant_documents(\"What is GCPATr?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0126ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mOkay, the user wants me to summarize a CMAPSS dataset that appears to be related to engine\u001b[0m\n",
      "\u001b[36mperformance monitoring and predicting Remaining Useful Life (RUL). From the context provided, I can\u001b[0m\n",
      "\u001b[36msee this is likely time-series sensor data for multiple engines over time. Each row seems to\u001b[0m\n",
      "\u001b[36mrepresent a different measurement point with several key components: - First column: Engine ID -\u001b[0m\n",
      "\u001b[36mSecond column: Time of reading - Third and fourth columns: Some operation-related values (always\u001b[0m\n",
      "\u001b[36m100.0 in these examples) - Remaining columns: Various engine sensor readings Hmm, looking at the\u001b[0m\n",
      "\u001b[36mdata patterns across multiple contexts, I notice some interesting characteristics about this\u001b[0m\n",
      "\u001b[36mdataset: The first two rows for each engine ID show very similar values except for slight\u001b[0m\n",
      "\u001b[36mvariations that could indicate real operational changes or measurement noise. There's a clear\u001b[0m\n",
      "\u001b[36mpattern where certain columns remain constant (like the third and fourth columns always being\u001b[0m\n",
      "\u001b[36m100.0) while others change slightly over time. I should point out this dataset appears to be\u001b[0m\n",
      "\u001b[36mstructured specifically for RUL prediction tasks, with multiple consecutive readings from each\u001b[0m\n",
      "\u001b[36mengine showing gradual degradation patterns. The data seems standardized - all entries are\u001b[0m\n",
      "\u001b[36mnumerical values that might represent normalized sensor readings or operational parameters. The\u001b[0m\n",
      "\u001b[36muser is probably working on predictive maintenance applications and needs to understand the\u001b[0m\n",
      "\u001b[36mstructure of this CMAPSS dataset before using it for training a machine learning model. They've\u001b[0m\n",
      "\u001b[36mprovided sample rows, suggesting they want me to focus on characterizing the general format rather\u001b[0m\n",
      "\u001b[36mthan analyzing specific engine data. I think I'll mention that the third column seems to represent\u001b[0m\n",
      "\u001b[36msome operation status or mode (with values like -0.0013) while others appear to be sensor readings\u001b[0m\n",
      "\u001b[36mthemselves. The dataset appears to contain multiple engines' time-series data, with each engine\u001b[0m\n",
      "\u001b[36mhaving several failure cycles represented by consecutive rows showing degradation patterns. This\u001b[0m\n",
      "\u001b[36mlooks like a standard predictive maintenance dataset where the goal would be to train models to\u001b[0m\n",
      "\u001b[36mrecognize degradation patterns and predict when an engine might fail based on its current state.\u001b[0m\n",
      "\u001b[36mI'll make sure to highlight this structure in my summary.\u001b[0m\n",
      "\n",
      "\n",
      "Okay, summarizing the provided CMAPSS dataset examples: 1. The first column is always **Engine ID**\n",
      "(e.g., \"95\", \"96\", \"97\"). 2. The second column represents the **time index** of a sensor reading\n",
      "(e.g., engine cycle number). 3. Columns three and four represent some form of **operation status**,\n",
      "but in these examples, they almost always have one value as `-0.0013` or `0.0032` etc. and another\n",
      "very close to zero (`-0.0005`, `-0.0003`, `-0.0002`) - sometimes the first operation value is 100.0\n",
      "(e.g., in \"95\" cycle 65). 4. Starting from column five onwards, most values are **sensor readings**\n",
      "or related parameters. * Columns 5 and 6 show engine operational modes (`100.0`, `518.67` etc.),\n",
      "which appear constant between consecutive cycles (e.g., always \"100.0\" for cycle index). * Columns\n",
      "7 to 9 look like pressure readings. * Columns 10 and 11 seem related to temperature or similar\n",
      "measurements (`14.62`, `21.60` etc.). They appear constant between cycles in these examples, except\n",
      "the very last value which does change slightly (e.g., \"555.06\" vs \"555.64\"). * Columns 12 to 14 are\n",
      "likely **sensor readings** (`2387.97`, `9077.08` etc.), and these values do show changes between\n",
      "consecutive cycles. * Column 15 appears constant (always \"1.30\" in the examples shown). * Columns\n",
      "16 to 18 look like vibration measurements (`47.08`, `522.29` etc.) - they change slightly. * Column\n",
      "19 is consistently labeled as **RUL** (Remaining Useful Life) prediction target, but the values\n",
      "provided (\"39.05\", \"38.92\") don't seem to represent actual RUL predictions for these specific\n",
      "points; rather, they might be part of a larger dataset where this column contains initial or future\n",
      "RUL estimates. * Columns 20 onwards (`0.03`, `391`, etc.) likely contain other sensor readings or\n",
      "potentially features derived from the raw data. Overall structure: Time-series sensor data for\n",
      "multiple engines, with columns representing Engine ID, Cycle Number (time), Operation Status,\n",
      "various Sensor Readings, and a column designated for Remaining Useful Life prediction targets.\n"
     ]
    }
   ],
   "source": [
    "answer2 = loaded_model.predict({\"query\": \"Can you summerize this dataset?\"})\n",
    "print_answer_formatted (answer2['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e820e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mOkay, let me try to figure this out. The user provided some context about the CMAPSS dataset and\u001b[0m\n",
      "\u001b[36mthen asked if I can predict the Remaining Useful Life (RUL) of a sampled sensor data from another\u001b[0m\n",
      "\u001b[36mmachine. First, looking at the context, it seems like there's a structure in each row. The first\u001b[0m\n",
      "\u001b[36mcolumn is an engine ID, the second is time, columns 3-5 are operation-related info, and then there\u001b[0m\n",
      "\u001b[36mare many more columns for sensor readings. So RUL prediction probably uses all these features\u001b[0m\n",
      "\u001b[36mexcept maybe the time or ID since we're predicting future life based on current state. But wait,\u001b[0m\n",
      "\u001b[36mhow does one row relate to another? The question mentions \"the second column of the training\u001b[0m\n",
      "\u001b[36mdataset,\" which is likely the target variable (RUL). However, without knowing what that actually\u001b[0m\n",
      "\u001b[36mrepresents in each sample—like whether it's a label for how much more time until failure or\u001b[0m\n",
      "\u001b[36msomething else—it's hard. Maybe the user assumes I know this dataset structure. Now, even if we\u001b[0m\n",
      "\u001b[36massume all columns after operations are sensor readings and their second column is RUL labels,\u001b[0m\n",
      "\u001b[36mthere's another issue: Each row might be part of different operational phases or health states. For\u001b[0m\n",
      "\u001b[36mexample, some rows could belong to engines that failed earlier, affecting how time and sensors\u001b[0m\n",
      "\u001b[36mcorrelate with remaining life. The user wants me to predict the RUL for a new data point they\u001b[0m\n",
      "\u001b[36mprovided at the end. But without seeing multiple failure times per engine in the dataset, I can't\u001b[0m\n",
      "\u001b[36mconfirm if this is possible. Maybe all samples are from different engines or varying conditions?\u001b[0m\n",
      "\u001b[36mAlso, predicting RUL typically requires knowing when failures occurred so that we can model\u001b[0m\n",
      "\u001b[36mdegradation curves. Without that information (like actual failure labels across time steps), how\u001b[0m\n",
      "\u001b[36mwould a model know what to predict exactly? The second column might be part of an existing dataset\u001b[0m\n",
      "\u001b[36mwith historical failure info. The query doesn't specify if this is labeled data or not, but from\u001b[0m\n",
      "\u001b[36mthe context examples given earlier by the user, they mentioned \"Remaining columns are sensor\u001b[0m\n",
      "\u001b[36mreadings\" and \"I would like to use this dataset to train a model.\" So maybe there's labeling\u001b[0m\n",
      "\u001b[36mimplied here through those second column values? But still... unless I have access to all\u001b[0m\n",
      "\u001b[36mhistorical failure times for each engine ID in the training data—something that might not be\u001b[0m\n",
      "\u001b[36mprovided—the task seems ambiguous. Maybe some rows are already past failures, others current\u001b[0m\n",
      "\u001b[36mstates? That would affect the approach. Since none of this information is given and the dataset\u001b[0m\n",
      "\u001b[36mstructure isn't fully clear without seeing more samples or knowing what those second column values\u001b[0m\n",
      "\u001b[36mrepresent exactly over multiple time points (I'm assuming they're failure labels), I can't\u001b[0m\n",
      "\u001b[36mconfidently say whether prediction is possible. The user might think that just any sensor data\u001b[0m\n",
      "\u001b[36mpoint would allow prediction, but RUL models usually need context from previous readings and\u001b[0m\n",
      "\u001b[36mknowledge about degradation patterns. Without explicit labeling or understanding the relationship\u001b[0m\n",
      "\u001b[36mbetween all these sensor values over time, predicting an arbitrary sample's remaining useful life\u001b[0m\n",
      "\u001b[36misn't feasible with this information alone.\u001b[0m\n",
      "\n",
      "\n",
      "I cannot predict the Remaining Useful Life (RUL) of a new sensor data point based on the limited\n",
      "examples provided. RUL prediction typically requires training on historical data that includes\n",
      "degradation trajectories and known failure points to learn patterns over time. The second column in\n",
      "your context appears to represent some form of label or target value, but without knowing how it\n",
      "relates to failure events across multiple time steps for each engine ID (e.g., whether it's the\n",
      "actual RUL at that timestamp), I cannot determine if a model can be trained from these examples\n",
      "alone. To answer your question definitively, I would need access to more comprehensive data showing\n",
      "degradation over time with corresponding failure labels and an understanding of how all variables\n",
      "interact within the dataset.\n"
     ]
    }
   ],
   "source": [
    "answer3 = loaded_model.predict({\"query\": \"I sample a sensor data from another machine. Depends on the dataset I give you, can you predict it's RUL?i,e. the second column of the training dataset.  1 31 -0.0006 0.0004 100.0 518.67 642.58 1581.22 1398.91 14.62 21.61 554.42 2388.08 9056.40 1.30 47.23 521.79 2388.06 8130.11 8.4024 0.03 393 2388 100.00 38.81 23.3552\"})\n",
    "print_answer_formatted (answer3['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6ac021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know what your previous question was. I have no memory of past interactions. Please provide\n",
      "the question you've asked before.\n"
     ]
    }
   ],
   "source": [
    "answer3 = loaded_model.predict({\"query\": \"Can you repeat my previous question?\"})\n",
    "print_answer_formatted (answer3['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ec541",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18272f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
